{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from mediawiki import MediaWiki\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk import tokenize\n",
    "from nltk.tag import StanfordNERTagger\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import unicodedata\n",
    "import timeit\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_locs = pd.read_csv('all_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove non english characters, everything in ()\n",
    "# Sort the dataframe\n",
    "for i,row in all_locs.iterrows():\n",
    "    aname = row['Area Name']\n",
    "    aname = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(aname))\n",
    "    all_locs.set_value(i,'Area Name',aname.strip().lower().capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../GDELT_2017/unrest_gdelt_2017_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for removing unnecessary characters.\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \" \", string)\n",
    "    string = re.sub(r\"\\'\", \" \", string)\n",
    "    string = re.sub(r\"\\\"\", \" \", string)\n",
    "    string = re.sub(r\"\\n\", \" \", string)\n",
    "    string = re.sub(r\"=\", \" \", string)\n",
    "    string = re.sub(r\"-\", \" \", string)\n",
    "    string = re.sub(r\"/\", \" \", string)\n",
    "    string = re.sub(r\"the\",\"\",string)\n",
    "    string = re.sub(r\",\",\"\",string)\n",
    "    return string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locs = set(all_locs['Area Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26524\n",
      "48368\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "all_counts = {}\n",
    "no_locations = 0;\n",
    "no_words = 0;\n",
    "for i,row in df.iterrows():\n",
    "    print(i)\n",
    "    test_data = row['content']\n",
    "    test_data = unicodedata.normalize(\"NFKD\", test_data)\n",
    "    test_data = clean_str(test_data)\n",
    "    text_sent = nltk.sent_tokenize(test_data)\n",
    "    for sent in text_sent:\n",
    "        text_tags = nltk.word_tokenize(sent)\n",
    "        text_tagged = nltk.pos_tag(text_tags)\n",
    "        for e,t in text_tagged:\n",
    "            if t == 'IN':\n",
    "                if e in all_counts:\n",
    "                    all_counts[e] = all_counts[e]+1\n",
    "                else:\n",
    "                    all_counts[e] = 1\n",
    "            if e in locs:\n",
    "                if e  in counts:\n",
    "                    counts[e] = counts[e]+1\n",
    "                else:\n",
    "                    counts[e] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amul': 1,\n",
       " 'Bhai': 6,\n",
       " 'Bhartiya': 1,\n",
       " 'But': 5,\n",
       " 'Dhani': 1,\n",
       " 'Dhoraji': 2,\n",
       " 'During': 1,\n",
       " 'Gandhi': 1,\n",
       " 'Gujarat': 3,\n",
       " 'Harda': 1,\n",
       " 'Himachal': 1,\n",
       " 'Hoshangabad': 2,\n",
       " 'It': 3,\n",
       " 'Jai': 1,\n",
       " 'Jamjodhpur': 2,\n",
       " 'Jamnagar': 1,\n",
       " 'Jetpur': 1,\n",
       " 'Kadva': 5,\n",
       " 'Kalawad': 1,\n",
       " 'Khodiyar': 1,\n",
       " 'Kisan': 2,\n",
       " 'Let': 1,\n",
       " 'Long': 1,\n",
       " 'Madhya': 1,\n",
       " 'Mava': 1,\n",
       " 'Mohammad': 1,\n",
       " 'Mohan': 1,\n",
       " 'Nana': 1,\n",
       " 'Narad': 1,\n",
       " 'On': 1,\n",
       " 'One': 1,\n",
       " 'Patel': 17,\n",
       " 'Pipalia': 2,\n",
       " 'Rajkot': 6,\n",
       " 'Ravi': 7,\n",
       " 'Sangh': 1,\n",
       " 'Sardar': 1,\n",
       " 'Say': 1,\n",
       " 'Shah': 1,\n",
       " 'Shiv': 1,\n",
       " 'Shivraj': 1,\n",
       " 'Shop': 2,\n",
       " 'Singh': 2,\n",
       " 'Thakur': 1,\n",
       " 'The': 11,\n",
       " 'There': 4,\n",
       " 'To': 1,\n",
       " 'Wankaner': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
