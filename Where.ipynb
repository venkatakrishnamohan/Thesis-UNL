{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from mediawiki import MediaWiki\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk import tokenize\n",
    "from nltk.tag import StanfordNERTagger\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import unicodedata\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Stanfors' default tagger\n",
    "st = StanfordNERTagger('/Users/venkatakrishnamohansunkara/Desktop/DM/stanford-ner-2018-02-27/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "  '/Users/venkatakrishnamohansunkara/Desktop/DM/stanford-ner-2018-02-27/stanford-ner.jar',\n",
    "   encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lists containing common prefixes and suffixes.\n",
    "prefix = ['at','by','near','in','from', 'on','to']\n",
    "# https://www.irfca.org/docs/place-names.html\n",
    "suffixes = ['nagar','colony','street','road','hill','river','temple']\n",
    "subs = ['pur','puram','ur','ghar','pura','ganj','abad','halli','keri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "#news_data = pd.read_csv('/Users/venkatakrishnamohansunkara/Desktop/DM/GDELT_2017/large_dataset/unrest_2017_ie_toi.csv', sep=',')\n",
    "df = pd.read_csv('../document similarity/document_similarity_hatt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>doc2vec</th>\n",
       "      <th>doc2veccosine</th>\n",
       "      <th>HATT embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>movie</td>\n",
       "      <td>Padmaavat: Why a Bollywood epic has sparked fi...</td>\n",
       "      <td>[ -9.05430984   1.71762216   1.08929253  -3.22...</td>\n",
       "      <td>[ 1.          0.94052142  0.9796434   0.926054...</td>\n",
       "      <td>[-0.04064541  0.5168978  -0.10278964 -0.406168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>lokpal</td>\n",
       "      <td>Anna Hazare on fast-unto-death demanding Jan L...</td>\n",
       "      <td>[ -4.08943748e+00   3.65195364e-01   4.3100047...</td>\n",
       "      <td>[ 0.94052142  1.          0.97000271  0.940714...</td>\n",
       "      <td>[ 1.61063448e-01  5.65693378e-01 -4.65846695e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>movie</td>\n",
       "      <td>A Film Has Inflamed Indians. But Moviegoers Mo...</td>\n",
       "      <td>[ -8.49335098   0.55525446   1.04886711  -3.75...</td>\n",
       "      <td>[ 0.9796434   0.97000271  1.          0.946262...</td>\n",
       "      <td>[ 1.81895524e-01  5.93335807e-01  6.25734329e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>movie</td>\n",
       "      <td>Indian police detain dozens protesting against...</td>\n",
       "      <td>[ -6.10597134   0.87642241   0.60653818  -3.09...</td>\n",
       "      <td>[ 0.92605472  0.9407143   0.94626272  0.999999...</td>\n",
       "      <td>[ 0.17177399  0.6309512  -0.04849247 -0.051712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>lokpal</td>\n",
       "      <td>Thousands Back Antigraft Hunger Strike in New ...</td>\n",
       "      <td>[-11.33139229   2.65446663   1.2543447   -0.94...</td>\n",
       "      <td>[ 0.8824504   0.86918712  0.90175384  0.953397...</td>\n",
       "      <td>[-0.06123626 -1.1703769   0.01185594 -0.637607...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>lokpal</td>\n",
       "      <td>Jan Lokpal Bill: Protests continue in support ...</td>\n",
       "      <td>[ -4.41828299e+00   5.35881042e-01   6.4218103...</td>\n",
       "      <td>[ 0.93510097  0.97717178  0.95960432  0.905399...</td>\n",
       "      <td>[-3.85057926e-02  3.16520661e-01 -2.69440532e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>lokpal</td>\n",
       "      <td>India corruption: Protests swell in support of...</td>\n",
       "      <td>[ -7.38126898   0.73874789   1.25690413  -4.65...</td>\n",
       "      <td>[ 0.97860324  0.96208191  0.97947335  0.944147...</td>\n",
       "      <td>[ 1.35564059e-01  5.99828005e-01 -5.64954542e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>lokpal</td>\n",
       "      <td>Hunger strike over Lokpal Bill as thousands pr...</td>\n",
       "      <td>[-5.09889364  0.64079404  0.13031445 -4.445450...</td>\n",
       "      <td>[ 0.95688981  0.98412955  0.96912926  0.928257...</td>\n",
       "      <td>[ 1.44097835e-01  4.18904036e-01 -1.80478878e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>movie</td>\n",
       "      <td>Padmaavat: Riots break out in India as protest...</td>\n",
       "      <td>[ -2.40009403e+00   6.57581329e-01   4.1137728...</td>\n",
       "      <td>[ 0.88772088  0.95705724  0.91422349  0.880223...</td>\n",
       "      <td>[ 0.03712982  0.63247323 -0.16278782 -0.318585...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1 category  \\\n",
       "0           0             0               0    movie   \n",
       "1           1             1               1   lokpal   \n",
       "2           2             2               2    movie   \n",
       "3           3             3               3    movie   \n",
       "4           4             4               4   lokpal   \n",
       "5           5             5               5   lokpal   \n",
       "6           6             6               6   lokpal   \n",
       "7           7             7               7   lokpal   \n",
       "8           8             8               8    movie   \n",
       "\n",
       "                                             content  \\\n",
       "0  Padmaavat: Why a Bollywood epic has sparked fi...   \n",
       "1  Anna Hazare on fast-unto-death demanding Jan L...   \n",
       "2  A Film Has Inflamed Indians. But Moviegoers Mo...   \n",
       "3  Indian police detain dozens protesting against...   \n",
       "4  Thousands Back Antigraft Hunger Strike in New ...   \n",
       "5  Jan Lokpal Bill: Protests continue in support ...   \n",
       "6  India corruption: Protests swell in support of...   \n",
       "7  Hunger strike over Lokpal Bill as thousands pr...   \n",
       "8  Padmaavat: Riots break out in India as protest...   \n",
       "\n",
       "                                             doc2vec  \\\n",
       "0  [ -9.05430984   1.71762216   1.08929253  -3.22...   \n",
       "1  [ -4.08943748e+00   3.65195364e-01   4.3100047...   \n",
       "2  [ -8.49335098   0.55525446   1.04886711  -3.75...   \n",
       "3  [ -6.10597134   0.87642241   0.60653818  -3.09...   \n",
       "4  [-11.33139229   2.65446663   1.2543447   -0.94...   \n",
       "5  [ -4.41828299e+00   5.35881042e-01   6.4218103...   \n",
       "6  [ -7.38126898   0.73874789   1.25690413  -4.65...   \n",
       "7  [-5.09889364  0.64079404  0.13031445 -4.445450...   \n",
       "8  [ -2.40009403e+00   6.57581329e-01   4.1137728...   \n",
       "\n",
       "                                       doc2veccosine  \\\n",
       "0  [ 1.          0.94052142  0.9796434   0.926054...   \n",
       "1  [ 0.94052142  1.          0.97000271  0.940714...   \n",
       "2  [ 0.9796434   0.97000271  1.          0.946262...   \n",
       "3  [ 0.92605472  0.9407143   0.94626272  0.999999...   \n",
       "4  [ 0.8824504   0.86918712  0.90175384  0.953397...   \n",
       "5  [ 0.93510097  0.97717178  0.95960432  0.905399...   \n",
       "6  [ 0.97860324  0.96208191  0.97947335  0.944147...   \n",
       "7  [ 0.95688981  0.98412955  0.96912926  0.928257...   \n",
       "8  [ 0.88772088  0.95705724  0.91422349  0.880223...   \n",
       "\n",
       "                                     HATT embeddings  \n",
       "0  [-0.04064541  0.5168978  -0.10278964 -0.406168...  \n",
       "1  [ 1.61063448e-01  5.65693378e-01 -4.65846695e-...  \n",
       "2  [ 1.81895524e-01  5.93335807e-01  6.25734329e-...  \n",
       "3  [ 0.17177399  0.6309512  -0.04849247 -0.051712...  \n",
       "4  [-0.06123626 -1.1703769   0.01185594 -0.637607...  \n",
       "5  [-3.85057926e-02  3.16520661e-01 -2.69440532e-...  \n",
       "6  [ 1.35564059e-01  5.99828005e-01 -5.64954542e-...  \n",
       "7  [ 1.44097835e-01  4.18904036e-01 -1.80478878e-...  \n",
       "8  [ 0.03712982  0.63247323 -0.16278782 -0.318585...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = df.iloc[5].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan Lokpal Bill: Protests continue in support of Anna Hazare in Punjab\\n\\nCHANDIGARH: Khap panchayats today joined the protests in support of Anna Hazare in Punjab and Haryana where the Gandhian\\'s supporters took out car and bike rallies and staged a demonstration outside Prime Minister Manmohan Singh\\'s private residence here.\\xa0\\n\\nAs the protests spread, people in rural areas were seen participating in demonstrations in support of Hazare.\\xa0\\n\\nKhap spokesman Suresh Koth said the khap panchayats (caste councils) in Haryana are observing a hunger strike in Jind, the Jat heartland of Haryana, and other places in support of Hazare\\'s movement.\\xa0\\n\\nIn Chandigarh, activists of various organisations staged a protest outside the Prime Minister\\'s private residence in Sector 11.\\xa0\\n\\nThe Chandigarh administration had yesterday promulgated prohibitory orders banning assembly of five or more persons outside the residences of five VIPs, including that of the Prime Minister.\\xa0\\n\\nThe Additional District Magistrate had imposed the orders within hours of Hazare\\'s supporters protesting outside the residence of Union Parliamentary Affairs Minister Pawan Bansal in Sector 28 yesterday.\\xa0\\n\\nRepresentatives of many NGOs are observing a fast in the city besides former Union Minister Harmohan Dhawan said.\\xa0\\n\\n\"The protest will continue till the government comes out with a strong Jan Lok Pal Bill to save the country from the menace of corruption,\" an activist said.\\xa0\\n\\nAt several places in the two states, youth were seen holding a box and seeking donations for Hazare\\'s movement whereas at other places people took out car and bike rallies.\\xa0\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for removing unnecessary characters.\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \" \", string)\n",
    "    string = re.sub(r\"\\'\", \" \", string)\n",
    "    string = re.sub(r\"\\\"\", \" \", string)\n",
    "    string = re.sub(r\"\\n\", \" \", string)\n",
    "    string = re.sub(r\"=\", \" \", string)\n",
    "    string = re.sub(r\"-\", \" \", string)\n",
    "    string = re.sub(r\"/\", \" \", string)\n",
    "    return string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = \"The attacks have raised grave concern both with the society and the government at large.\"\n",
    "text_tags = nltk.word_tokenize(sent)\n",
    "original_tags = st.tag(text_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('attacks', 'O'),\n",
       " ('have', 'O'),\n",
       " ('raised', 'O'),\n",
       " ('grave', 'O'),\n",
       " ('concern', 'O'),\n",
       " ('both', 'O'),\n",
       " ('with', 'O'),\n",
       " ('the', 'O'),\n",
       " ('society', 'O'),\n",
       " ('and', 'O'),\n",
       " ('the', 'O'),\n",
       " ('government', 'O'),\n",
       " ('at', 'O'),\n",
       " ('large', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = unicodedata.normalize(\"NFKD\", test_data)\n",
    "test_data = clean_str(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  20.79032592900012\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "# Convert the entire document data to sentences.\n",
    "text_sent = nltk.sent_tokenize(test_data)\n",
    "stanford = []\n",
    "noun_phrases = []\n",
    "#new_model = []\n",
    "locations = []\n",
    "# other are prefixes\n",
    "other = []\n",
    "suffix_locations = []\n",
    "sub_locations = []\n",
    "all_words = []\n",
    "# Iterate over all the sentences.\n",
    "for sent in text_sent:\n",
    "    # Convert the sentence to words\n",
    "    text_tags = nltk.word_tokenize(sent)\n",
    "    all_words+=[text_tags]\n",
    "    # Get the NER for the words.\n",
    "    original_tags = st.tag(text_tags)\n",
    "    l = len(original_tags)\n",
    "    i=0;\n",
    "    # Iterate over the tagged words.\n",
    "    while i<l:\n",
    "        #print(i)\n",
    "        e,t = original_tags[i];\n",
    "        # If it's a location, then check the next 3 words.\n",
    "        if t == 'LOCATION':\n",
    "            j = 1;\n",
    "            s = e; \n",
    "            # Verify the tags for the next 3 words.\n",
    "            while i+j<len(original_tags):\n",
    "                # If the next words are also locations, then concatenate them to make a large string.\n",
    "                if original_tags[i+j][1] == 'LOCATION':\n",
    "                    s = s+\" \"+original_tags[i+j][0];\n",
    "                    j+=1;\n",
    "                else:\n",
    "                    break;\n",
    "            i = i+j;\n",
    "            # Save the locations to a locations list\n",
    "            locations+=[s];\n",
    "        else:\n",
    "            i=i+1;\n",
    "    # Get the POS tag for the words.\n",
    "    text_tagged = nltk.pos_tag(text_tags)\n",
    "    l = len(text_tagged)\n",
    "    i=0;\n",
    "    # iterate over the tagged words.\n",
    "    while i<l:\n",
    "        #print(i)\n",
    "        e,t = text_tagged[i];\n",
    "        # If the current word is a Noun phrase.\n",
    "        if t == 'NNP':\n",
    "            j = 1;\n",
    "            s = e;\n",
    "            # verify the tags for the next 3 words.\n",
    "            while i+j<len(text_tagged):\n",
    "                # If the next words are also nouns, then concatenate them to make a large string.\n",
    "                if text_tagged[i+j][1] in ['NNP','NN','NNS','NNPS']:\n",
    "                    s = s+\" \"+text_tagged[i+j][0];\n",
    "                    j+=1;\n",
    "                else:\n",
    "                    break;\n",
    "            i = i+j;\n",
    "            # Save the noun phrases to a noun_phrases list\n",
    "            noun_phrases+=[s];\n",
    "        else:\n",
    "            i=i+1;\n",
    "    # Convert the words to lower case so as to compare with the prefixes.\n",
    "    text_tags = [t.lower() for t in text_tags]\n",
    "    # Go through all the prefixes.\n",
    "    for k in prefix:\n",
    "        # If the prefix is not present in the sentence then an error occurs. So, we use a try, catch block\n",
    "        try:\n",
    "            # Get the position the prefix word in a sentence.\n",
    "            index = text_tags.index(k)\n",
    "            # If the word after the prefix word is a noun, then consider it.\n",
    "            if text_tagged[index+1][1] == 'NNP':\n",
    "                j = 1;\n",
    "                s = text_tagged[index+1][0]; \n",
    "                # Verify if it is a phrase by considering the next 3 words.\n",
    "                while index+j<len(text_tagged):\n",
    "                    if text_tagged[index+j+1][1] in ['NNP','NN','NNS','NNPS']:\n",
    "                        s = s+\" \"+text_tagged[index+j+1][0];\n",
    "                        j+=1;\n",
    "                    else:\n",
    "                        break;\n",
    "                # Save the words after the prefix words in to other list.\n",
    "                other = other + [s]\n",
    "        except:\n",
    "            continue\n",
    "    # Iterate through the list of suffixes.\n",
    "    for s in suffixes:\n",
    "        try:\n",
    "            # get the position of the suffix word in the sentence\n",
    "            index = text_tags.index(s)\n",
    "            # If the word before a suffix word is a noun phrase, then consider it.\n",
    "            if text_tagged[index-1][1] == 'NNP':\n",
    "                j = 1;\n",
    "                stri = text_tagged[index-1][0]; \n",
    "                # verify if the preceeding 3 words are nouns.\n",
    "                while j<3 and index+j<len(text_tagged):\n",
    "                    if text_tagged[index-j-1][1] in ['NNP','NN','NNS','NNPS']:\n",
    "                        stri = stri+\" \"+text_tagged[index-j-1][0];\n",
    "                        j+=1;\n",
    "                    else:\n",
    "                        break;\n",
    "                # Reverse the preceeding words list\n",
    "                stri = ' '.join(stri.split(\" \")[-1::-1]) \n",
    "                # If the string is not already present in other lists, then add it to the suffix_locations list.\n",
    "                if stri not in locations or stri not in noun_phrases or stri not in other:\n",
    "                    stri = stri+\" \"+ s;\n",
    "                    if stri not in locations or stri not in noun_phrases or stri not in other:\n",
    "                        suffix_locations = suffix_locations + [stri]\n",
    "        except:\n",
    "            continue\n",
    "    for sub in subs:\n",
    "        # get the words which contain any of the sub_string from the subs list.\n",
    "        su = [te for te in text_tags if te.endswith(sub)]\n",
    "        try:\n",
    "            for sub1 in su:\n",
    "                # Get the position of the word from the sentence.\n",
    "                index = text_tags.index(sub1)\n",
    "                # If it is a Noun, then consider it.\n",
    "                if text_tagged[index][1] in ['NNP','NN','NNS','NNPS']:\n",
    "                    sub_locations = sub_locations + [text_tagged[index][0]]\n",
    "        except:\n",
    "            continue\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) \n",
    "all_words = [x for sublist in all_words for x in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_locations = locations+other+suffix_locations+sub_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Punjab CHANDIGARH',\n",
       " 'Punjab',\n",
       " 'Haryana',\n",
       " 'Haryana',\n",
       " 'Jind',\n",
       " 'Haryana',\n",
       " 'Chandigarh',\n",
       " 'Chandigarh',\n",
       " 'Haryana',\n",
       " 'Chandigarh',\n",
       " 'Sector']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_locations_nodups = []\n",
    "for i in all_locations:\n",
    "    if i.lower() not in [j.lower() for j in all_locations_nodups]:\n",
    "        all_locations_nodups.append(i);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5 different conditions for ranking the data.\n",
    "# A metric for similarity measures.\n",
    "locations_list = all_locations_nodups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_freq = nltk.FreqDist(all_words)\n",
    "#words_freq = sorted(words_freq.items(), key=lambda x: x[1])\n",
    "words_freq = dict(words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = np.asarray(all_words)\n",
    "# get all positional occurences of a word in the document\n",
    "pos_occurences = {k:-1 for k in locations_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = [\"strike\",\n",
    "\"unrest\",\n",
    "\"masses\",\n",
    "\"protest\",\n",
    "\"demonstration\",\n",
    "\"worker\",\n",
    "\"union\",\n",
    "\"company\",\n",
    "\"caste\",\n",
    "\"religious\",\n",
    "\"ethnic\",\n",
    "\"reformed\",\n",
    "\"rebellion\",\n",
    "\"defense\",\n",
    "\"violence\",\n",
    "\"war\",\n",
    "\"armed\",\n",
    "\"fight\",\n",
    "\"Right\",\n",
    "\"free\",\n",
    "\"freedom\",\n",
    "\"liberty\",\n",
    "\"justice\",\n",
    "\"Fair\",\n",
    "\"unfair\",\n",
    "\"unequal\",\n",
    "\"terror\",\n",
    "\"extreme\",\n",
    "\"Bomb\",\n",
    "\"IED\",\n",
    "\"weapon\",\n",
    "\"gun\",\n",
    "\"wmd\",\n",
    "\"threat\",\n",
    "\"suicide\",\n",
    "\"murder\",\n",
    "\"Kill\",\n",
    "\"death\",\n",
    "\"explosive\",\n",
    "\"military\",\n",
    "\"police\",\n",
    "\"elite\",\n",
    "\"government\",\n",
    "\"oppresive\",\n",
    "\"power\",\n",
    "\"regime\",\n",
    "\"fraud\",\n",
    "\"corruption\",\n",
    "\"coup\",\n",
    "\"safety\",\n",
    "\"secure\",\n",
    "\"insecure\",\n",
    "\"protect\",\n",
    "\"enemy\",\n",
    "\"resist\",\n",
    "\"hostage\",\n",
    "\"truce\",\n",
    "\"fire\",\n",
    "\"greed\",\n",
    "\"panic\",\n",
    "\"inflation\",\n",
    "\"Price\",\n",
    "\"Food\",\n",
    "\"Water\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = [v.lower() for v in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1c54d030c831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_words\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpos_occurences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mno_of_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indices' is not defined"
     ]
    }
   ],
   "source": [
    "pos_threshold = len(all_words)\n",
    "all_locations = {k:[pos_threshold+1,'r',''] for k in locations_list}\n",
    "for location in list(all_locations.keys()):\n",
    "    sub_locations = location.split(' ')\n",
    "    if len(sub_locations) > 1:\n",
    "        last_subloc = sub_locations[-1]\n",
    "        first_subloc = sub_locations[0]\n",
    "        last_indices = np.where(all_words == last_subloc)[0]\n",
    "        first_indices = np.where(all_words == first_subloc)[0]\n",
    "        first_indices = list(first_indices)\n",
    "        last_indices = list(last_indices)\n",
    "        diff = [a_i - b_i for a_i, b_i in zip(last_indices, first_indices)]\n",
    "        first_indices = first_indices[diff == len(sub_locations)]\n",
    "        pos_occurences[location] = first_indices\n",
    "    else:\n",
    "        indices = np.where(all_words == location)[0]\n",
    "        pos_occurences[location] = list(indices)\n",
    "    print(indices)\n",
    "    if len(indices)>0:\n",
    "        no_of_indices = len(indices)\n",
    "        i=0\n",
    "        while i< no_of_indices:\n",
    "            j=0\n",
    "            while j<pos_threshold and indices[i]+j<len(all_words):\n",
    "                if all_words[indices[i]+j].lower() in vocab:\n",
    "                    if j<all_locations[location][0]:\n",
    "                        all_locations[location] = [j,'r',all_words[indices[i]+j].lower()]\n",
    "                    break\n",
    "                j=j+1\n",
    "            j=0\n",
    "            while j<pos_threshold and indices[i]-j>=0:\n",
    "                if all_words[indices[i]-j].lower() in vocab:\n",
    "                    if j<all_locations[location][0]:\n",
    "                        all_locations[location] = [j,'l',all_words[indices[i]-j].lower()]\n",
    "                    break\n",
    "                j=j+1\n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The nearest position of an unrest keyword.\n",
    "all_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The position of the word in the entire document.\n",
    "pos_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations_freq = {k:0 for k in locations_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in locations_list:\n",
    "    sub_locations = k.split(' ')\n",
    "    if len(sub_locations) > 1:\n",
    "        min_count = words_freq[sub_locations[0]]\n",
    "        for s in sub_locations:\n",
    "            if words_freq[s]<min_count:\n",
    "                min_count = words_freq[s];\n",
    "    else:\n",
    "        min_count = words_freq[k]\n",
    "    locations_freq[k] = min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The number of occurences of a location in the document.\n",
    "# Some cases were ignored.\n",
    "locations_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_no = {k:[] for k in locations_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for loc in locations_list:\n",
    "    sub_locations = loc.split(' ')\n",
    "    sent_no = 0\n",
    "    for sent in text_sent:\n",
    "        text_tags = nltk.word_tokenize(sent)\n",
    "        i=0\n",
    "        for s in sub_locations:\n",
    "            if s in text_tags:\n",
    "                i+=1\n",
    "        if i == len(sub_locations):\n",
    "            sentence_no[loc] = sentence_no[loc]+[sent_no]\n",
    "        sent_no+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The sentence number in which the word is present.\n",
    "sentence_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_scores = {k:0 for k in locations_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_no_words = len(all_words)\n",
    "total_no_sentences = len(text_sent)\n",
    "for loc in locations_list:\n",
    "    fs = (locations_freq[loc]/total_no_words) + (1-(pos_occurences[loc]/total_no_words)) \\\n",
    "            + (1-(all_locations[loc][0]/pos_threshold)) + (1-(sentence_no[loc][0]/total_no_sentences))\n",
    "    final_scores[loc] = fs/4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_locs = pd.read_csv('all_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict_keys' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-058fc767f461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_locations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict_keys' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "all_locations = all_locations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_locations = list(all_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Punjab CHANDIGARH', 'Punjab', 'Haryana', 'Jind', 'Chandigarh', 'Sector']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove non english characters, everything in ()\n",
    "# Sort the dataframe\n",
    "for i,row in all_locs.iterrows():\n",
    "    aname = row['Area Name']\n",
    "    aname = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(aname))\n",
    "    all_locs.set_value(i,'Area Name',aname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bathar '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", \"Bathar (480)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_locs.to_csv('all_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = all_locs['Area Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = list(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punjab CHANDIGARH\n",
      "Punjab\n",
      "Haryana\n",
      "Jind\n",
      "Chandigarh\n",
      "Sector\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame(columns=['Area Name','SUB_DISTRICT NAME','DISTRICT NAME','STATE NAME','final_score'])\n",
    "i=0;\n",
    "for name in locations_list:\n",
    "    # Extract the closest match > 98%.\n",
    "    # If more than one extract all \n",
    "    print(name)\n",
    "    def get_ratio(row):\n",
    "        aname = row['Area Name']\n",
    "        return fuzz.ratio(aname,name)\n",
    "    found_locs = all_locs[all_locs.apply(get_ratio, axis=1) > 98]\n",
    "    if found_locs.shape[0]>0:\n",
    "        for j,row in found_locs.iterrows():\n",
    "            final_df.set_value(i,'Area Name',row['Area Name'])\n",
    "            final_df.set_value(i,'SUB_DISTRICT NAME',row['SUB-DISTRICT NAME'])\n",
    "            final_df.set_value(i,'DISTRICT NAME',row['DISTRICT NAME'])\n",
    "            final_df.set_value(i,'STATE NAME',row['STATE NAME'])\n",
    "            #final_df.set_value(i,'final_score',score)\n",
    "            i+=1\n",
    "    else:\n",
    "        final_df.set_value(i,'Area Name',name)\n",
    "        final_df.set_value(i,'SUB_DISTRICT NAME','None')\n",
    "        final_df.set_value(i,'DISTRICT NAME','None')\n",
    "        final_df.set_value(i,'STATE NAME','None')\n",
    "        #final_df.set_value(i,'final_score',score)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area Name</th>\n",
       "      <th>SUB_DISTRICT NAME</th>\n",
       "      <th>DISTRICT NAME</th>\n",
       "      <th>STATE NAME</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Punjab CHANDIGARH</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>India</td>\n",
       "      <td>India</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>Bilari</td>\n",
       "      <td>Moradabad</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>Amroha</td>\n",
       "      <td>Jyotiba Phule Nagar</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>Hasanpur</td>\n",
       "      <td>Jyotiba Phule Nagar</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>India</td>\n",
       "      <td>India</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jind</td>\n",
       "      <td>Jind</td>\n",
       "      <td>Jind</td>\n",
       "      <td>HARYANA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jind</td>\n",
       "      <td>India</td>\n",
       "      <td>India</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>Thakurpukur Mahestola</td>\n",
       "      <td>South Twenty Four Parganas</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>Ramgarh</td>\n",
       "      <td>Alwar</td>\n",
       "      <td>RAJASTHAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>CHANDIGARH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>Berhampur</td>\n",
       "      <td>Baleshwar</td>\n",
       "      <td>ODISHA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>India</td>\n",
       "      <td>India</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sector</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Area Name      SUB_DISTRICT NAME               DISTRICT NAME  \\\n",
       "0   Punjab CHANDIGARH                   None                        None   \n",
       "1              Punjab                  India                       India   \n",
       "5             Haryana                 Bilari                   Moradabad   \n",
       "6             Haryana                 Amroha         Jyotiba Phule Nagar   \n",
       "7             Haryana               Hasanpur         Jyotiba Phule Nagar   \n",
       "8             Haryana                  India                       India   \n",
       "10               Jind                   Jind                        Jind   \n",
       "12               Jind                  India                       India   \n",
       "14         Chandigarh  Thakurpukur Mahestola  South Twenty Four Parganas   \n",
       "15         Chandigarh                Ramgarh                       Alwar   \n",
       "16         Chandigarh             Chandigarh                  Chandigarh   \n",
       "18         Chandigarh             Berhampur                    Baleshwar   \n",
       "19         Chandigarh                  India                       India   \n",
       "24             Sector                   None                        None   \n",
       "\n",
       "       STATE NAME final_score  \n",
       "0            None         NaN  \n",
       "1           India         NaN  \n",
       "5   UTTAR PRADESH         NaN  \n",
       "6   UTTAR PRADESH         NaN  \n",
       "7   UTTAR PRADESH         NaN  \n",
       "8           India         NaN  \n",
       "10        HARYANA         NaN  \n",
       "12          India         NaN  \n",
       "14    WEST BENGAL         NaN  \n",
       "15      RAJASTHAN         NaN  \n",
       "16     CHANDIGARH         NaN  \n",
       "18         ODISHA         NaN  \n",
       "19          India         NaN  \n",
       "24           None         NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min distance of the nearest unrest keyword, first word occurence of a location mention,...\n",
    "# first sentence occurence of a location mention, frequency of a word as the components of the final_score.\n",
    "final_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan Lokpal Bill: Protests continue in support of Anna Hazare in Punjab  CHANDIGARH: Khap panchayats today joined the protests in support of Anna Hazare in Punjab and Haryana where the Gandhian s supporters took out car and bike rallies and staged a demonstration outside Prime Minister Manmohan Singh s private residence here.   As the protests spread, people in rural areas were seen participating in demonstrations in support of Hazare.   Khap spokesman Suresh Koth said the khap panchayats (caste councils) in Haryana are observing a hunger strike in Jind, the Jat heartland of Haryana, and other places in support of Hazare s movement.   In Chandigarh, activists of various organisations staged a protest outside the Prime Minister s private residence in Sector 11.   The Chandigarh administration had yesterday promulgated prohibitory orders banning assembly of five or more persons outside the residences of five VIPs, including that of the Prime Minister.   The Additional District Magistrate had imposed the orders within hours of Hazare s supporters protesting outside the residence of Union Parliamentary Affairs Minister Pawan Bansal in Sector 28 yesterday.   Representatives of many NGOs are observing a fast in the city besides former Union Minister Harmohan Dhawan said.    The protest will continue till the government comes out with a strong Jan Lok Pal Bill to save the country from the menace of corruption,  an activist said.   At several places in the two states, youth were seen holding a box and seeking donations for Hazare s movement whereas at other places people took out car and bike rallies.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
